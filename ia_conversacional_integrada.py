#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
IA Conversacional Integrada BMC Uruguay
Sistema de IA que aprende y evoluciona constantemente
"""

import json
import datetime
import re
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from decimal import Decimal
import random
from base_conocimiento_dinamica import BaseConocimientoDinamica, InteraccionCliente
from motor_analisis_conversiones import MotorAnalisisConversiones
from sistema_cotizaciones import (
    SistemaCotizacionesBMC,
    Cliente,
    EspecificacionCotizacion,
)
from utils_cotizaciones import (
    obtener_datos_faltantes,
    formatear_mensaje_faltantes,
    construir_contexto_validacion,
)

# OpenAI integration
try:
    from openai import OpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("Warning: OpenAI package not installed. Using pattern matching only.")


@dataclass
class ContextoConversacion:
    """Contexto de una conversaci√≥n en curso"""

    cliente_id: str
    sesion_id: str
    mensajes_intercambiados: List[Dict[str, Any]]
    intencion_actual: str
    entidades_extraidas: Dict[str, Any]
    estado_cotizacion: str
    datos_cliente: Dict[str, Any]
    datos_producto: Dict[str, Any]
    historial_interacciones: List[str]
    confianza_respuesta: float
    timestamp_inicio: datetime.datetime
    timestamp_ultima_actividad: datetime.datetime


@dataclass
class RespuestaIA:
    """Respuesta generada por la IA"""

    mensaje: str
    tipo_respuesta: str  # informativa, pregunta, cotizacion, seguimiento
    acciones_sugeridas: List[str]
    confianza: float
    fuentes_conocimiento: List[str]
    personalizacion: Dict[str, Any]
    timestamp: datetime.datetime


class IAConversacionalIntegrada:
    """IA Conversacional que aprende y evoluciona constantemente"""

    def __init__(self):
        self.base_conocimiento = BaseConocimientoDinamica()
        self.motor_analisis = MotorAnalisisConversiones(self.base_conocimiento)
        self.sistema_cotizaciones = SistemaCotizacionesBMC()
        self.conversaciones_activas = {}
        self.patrones_respuesta = {}
        self.entidades_reconocidas = {}

        # Shared context service for multi-agent system
        try:
            import sys
            from pathlib import Path

            python_scripts_path = Path(__file__).parent / "python-scripts"
            if str(python_scripts_path) not in sys.path:
                sys.path.insert(0, str(python_scripts_path))
            from shared_context_service import get_shared_context_service

            self.shared_context_service = get_shared_context_service()
            self.use_shared_context = True
        except Exception as e:
            self.shared_context_service = None
            self.use_shared_context = False
            print(f"Warning: Shared context service not available: {e}")

        # OpenAI configuration
        self.use_ai = False
        self.openai_client = None
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

        if OPENAI_AVAILABLE:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                try:
                    self.openai_client = OpenAI(api_key=api_key)
                    self.use_ai = True
                    print("‚úÖ OpenAI integration enabled")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error initializing OpenAI: {e}")
                    self.use_ai = False
            else:
                print("‚ö†Ô∏è OPENAI_API_KEY not set, using pattern matching only")
        else:
            print("‚ö†Ô∏è OpenAI package not available, using pattern matching only")

        self.cargar_configuracion_inicial()

    def cargar_configuracion_inicial(self):
        """Carga la configuraci√≥n inicial de la IA"""
        # Configurar sistema de cotizaciones
        self.sistema_cotizaciones.actualizar_precio_producto(
            "isodec", Decimal("150.00")
        )
        self.sistema_cotizaciones.actualizar_precio_producto(
            "poliestireno", Decimal("120.00")
        )
        self.sistema_cotizaciones.actualizar_precio_producto(
            "lana_roca", Decimal("140.00")
        )

        # Cargar patrones de respuesta iniciales
        self.patrones_respuesta = {
            "saludo": [
                "¬°Hola! Soy tu asistente de cotizaciones de BMC Uruguay. ¬øEn qu√© puedo ayudarte?",
                "¬°Buenos d√≠as! Estoy aqu√≠ para ayudarte con tus consultas de aislamiento t√©rmico.",
                "¬°Hola! ¬øTe interesa cotizar alg√∫n producto de aislamiento t√©rmico?",
            ],
            "despedida": [
                "¬°Gracias por contactar BMC Uruguay! Que tengas un excelente d√≠a.",
                "Ha sido un placer ayudarte. ¬°Hasta la pr√≥xima!",
                "Espero haber sido de ayuda. ¬°Que tengas un gran d√≠a!",
            ],
            "consulta_producto": [
                "Te ayudo con informaci√≥n sobre nuestros productos de aislamiento t√©rmico.",
                "Tenemos varios productos disponibles. ¬øCu√°l te interesa conocer?",
                "Perfecto, te explico las caracter√≠sticas de nuestros productos.",
            ],
            "cotizacion": [
                "¬°Excelente! Vamos a crear tu cotizaci√≥n paso a paso.",
                "Perfecto, necesito algunos datos para darte el precio exacto.",
                "Genial, te ayudo a cotizar el producto que necesitas.",
            ],
        }

        # Cargar entidades reconocidas
        self.entidades_reconocidas = {
            "productos": ["isodec", "poliestireno", "lana de roca", "lana_roca"],
            "espesores": ["50mm", "75mm", "100mm", "125mm", "150mm"],
            "colores": ["blanco", "gris", "personalizado"],
            "aplicaciones": [
                "casa",
                "edificio",
                "comercial",
                "industrial",
                "residencial",
            ],
            "objeciones": ["caro", "costoso", "no estoy seguro", "necesito pensarlo"],
            "intenciones": [
                "cotizar",
                "precio",
                "informacion",
                "caracteristicas",
                "instalacion",
            ],
        }

    def procesar_mensaje(
        self, mensaje: str, cliente_id: str, sesion_id: str = None
    ) -> RespuestaIA:
        """Procesa un mensaje del cliente y genera respuesta"""
        if not sesion_id:
            sesion_id = f"sesion_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}"

        # Obtener o crear contexto de conversaci√≥n
        contexto = self._obtener_contexto_conversacion(cliente_id, sesion_id)

        # Actualizar contexto con nuevo mensaje
        self._actualizar_contexto(contexto, mensaje)

        # Analizar mensaje
        intencion = self._analizar_intencion(mensaje)
        entidades = self._extraer_entidades(mensaje)

        # Generar respuesta
        respuesta = self._generar_respuesta_inteligente(
            mensaje, intencion, entidades, contexto
        )

        # Registrar interacci√≥n
        self._registrar_interaccion(mensaje, respuesta, contexto)

        # Actualizar conocimiento
        self._actualizar_conocimiento_conversacion(contexto, respuesta)

        # Save to shared context service
        if (
            self.use_shared_context
            and self.shared_context_service
            and contexto.sesion_id
        ):
            try:
                # Add assistant message
                self.shared_context_service.add_message(
                    contexto.sesion_id,
                    respuesta.mensaje,
                    "assistant",
                    {
                        "intent": intencion,
                        "entities": entidades,
                        "confidence": respuesta.confianza,
                    },
                )
                # Save full context
                context_dict = {
                    "user_phone": contexto.cliente_id,
                    "cliente_id": contexto.cliente_id,
                    "intent": contexto.intencion_actual,
                    "entities": contexto.entidades_extraidas,
                    "quote_state": {
                        "estado": contexto.estado_cotizacion,
                        "datos_cliente": contexto.datos_cliente,
                        "datos_producto": contexto.datos_producto,
                    },
                    "messages": [
                        {
                            "role": msg.get("tipo") == "cliente"
                            and "user"
                            or "assistant",
                            "content": msg.get("mensaje", ""),
                            "timestamp": msg.get("timestamp", datetime.datetime.now()),
                        }
                        for msg in contexto.mensajes_intercambiados
                    ],
                }
                self.shared_context_service.save_context(
                    contexto.sesion_id, context_dict
                )
            except Exception as e:
                print(f"Warning: Failed to save context to shared service: {e}")

        return respuesta

    def _obtener_contexto_conversacion(
        self, cliente_id: str, sesion_id: str
    ) -> ContextoConversacion:
        """Obtiene o crea el contexto de una conversaci√≥n"""
        clave_contexto = f"{cliente_id}_{sesion_id}"

        # Try to load from shared context service first
        if self.use_shared_context and self.shared_context_service and sesion_id:
            try:
                shared_context = self.shared_context_service.get_context(
                    sesion_id, cliente_id
                )
                if shared_context:
                    # Convert shared context to ContextoConversacion
                    contexto = ContextoConversacion(
                        cliente_id=cliente_id,
                        sesion_id=sesion_id,
                        mensajes_intercambiados=[
                            {
                                "tipo": msg.get("role") == "user"
                                and "cliente"
                                or "asistente",
                                "mensaje": msg.get("content", ""),
                                "timestamp": msg.get(
                                    "timestamp", datetime.datetime.now()
                                ),
                            }
                            for msg in shared_context.get("messages", [])
                        ],
                        intencion_actual=shared_context.get("intent", "general"),
                        entidades_extraidas=shared_context.get("entities", {}),
                        estado_cotizacion=shared_context.get("quote_state", {}).get(
                            "estado", "inicial"
                        ),
                        datos_cliente=shared_context.get("quote_state", {}).get(
                            "datos_cliente", {}
                        ),
                        datos_producto=shared_context.get("quote_state", {}).get(
                            "datos_producto", {}
                        ),
                        historial_interacciones=[],
                        confianza_respuesta=0.8,
                        timestamp_inicio=datetime.datetime.now(),
                        timestamp_ultima_actividad=datetime.datetime.now(),
                    )
                    # Store in active conversations for backward compatibility
                    self.conversaciones_activas[clave_contexto] = contexto
                    return contexto
            except Exception as e:
                print(f"Warning: Failed to load context from shared service: {e}")

        # Fallback to in-memory
        if clave_contexto in self.conversaciones_activas:
            return self.conversaciones_activas[clave_contexto]

        # Crear nuevo contexto
        contexto = ContextoConversacion(
            cliente_id=cliente_id,
            sesion_id=sesion_id,
            mensajes_intercambiados=[],
            intencion_actual="",
            entidades_extraidas={},
            estado_cotizacion="inicial",
            datos_cliente={},
            datos_producto={},
            historial_interacciones=[],
            confianza_respuesta=0.0,
            timestamp_inicio=datetime.datetime.now(),
            timestamp_ultima_actividad=datetime.datetime.now(),
        )

        self.conversaciones_activas[clave_contexto] = contexto
        return contexto

    def _actualizar_contexto(self, contexto: ContextoConversacion, mensaje: str):
        """Actualiza el contexto con un nuevo mensaje"""
        contexto.mensajes_intercambiados.append(
            {
                "tipo": "cliente",
                "mensaje": mensaje,
                "timestamp": datetime.datetime.now().isoformat(),
            }
        )
        contexto.timestamp_ultima_actividad = datetime.datetime.now()

    def _analizar_intencion(self, mensaje: str) -> str:
        """Analiza la intenci√≥n del mensaje del cliente"""
        mensaje_lower = mensaje.lower()

        # Patrones de intenci√≥n
        patrones_intencion = {
            "saludo": ["hola", "buenos", "buenas", "hi", "hello"],
            "despedida": ["gracias", "chau", "adios", "bye", "hasta luego"],
            "cotizacion": ["cotizar", "precio", "costo", "cuanto", "presupuesto"],
            "informacion": [
                "informacion",
                "informaci√≥n",
                "caracteristicas",
                "especificaciones",
                "que es",
                "necesito",
                "sobre",
                "acerca",
                "techos",
                "techo",
                "aislamiento",
            ],
            "producto": ["isodec", "poliestireno", "lana", "producto", "productos"],
            "instalacion": ["instalar", "instalacion", "montaje", "colocacion"],
            "servicio": ["servicio", "garantia", "soporte", "atenci√≥n"],
            "objecion": ["caro", "costoso", "no estoy seguro", "dudar"],
        }

        # Calcular puntuaci√≥n para cada intenci√≥n
        puntuaciones = {}
        for intencion, palabras in patrones_intencion.items():
            puntuacion = sum(1 for palabra in palabras if palabra in mensaje_lower)
            puntuaciones[intencion] = puntuacion

        # Retornar intenci√≥n con mayor puntuaci√≥n
        if puntuaciones:
            intencion_principal = max(puntuaciones, key=puntuaciones.get)
            if puntuaciones[intencion_principal] > 0:
                return intencion_principal

        return "general"

    def _extraer_entidades(self, mensaje: str) -> Dict[str, Any]:
        """Extrae entidades del mensaje"""
        mensaje_lower = mensaje.lower()
        entidades = {}

        # Extraer productos
        productos_encontrados = []
        for producto in self.entidades_reconocidas["productos"]:
            if producto in mensaje_lower:
                productos_encontrados.append(producto)
        if productos_encontrados:
            entidades["productos"] = productos_encontrados

        # Extraer espesores
        espesores_encontrados = []
        for espesor in self.entidades_reconocidas["espesores"]:
            if espesor in mensaje_lower:
                espesores_encontrados.append(espesor)
        if espesores_encontrados:
            entidades["espesores"] = espesores_encontrados

        # Extraer colores
        colores_encontrados = []
        for color in self.entidades_reconocidas["colores"]:
            if color in mensaje_lower:
                colores_encontrados.append(color)
        if colores_encontrados:
            entidades["colores"] = colores_encontrados

        # Extraer dimensiones
        dimensiones = self._extraer_dimensiones(mensaje)
        if dimensiones:
            entidades["dimensiones"] = dimensiones

        # Extraer n√∫meros de tel√©fono
        telefono = self._extraer_telefono(mensaje)
        if telefono:
            entidades["telefono"] = telefono

        # Extraer nombre y apellido
        nombre_apellido = self._extraer_nombre_apellido(mensaje)
        if nombre_apellido:
            entidades["nombre"] = nombre_apellido["nombre"]
            entidades["apellido"] = nombre_apellido["apellido"]

        return entidades

    def _extraer_dimensiones(self, mensaje: str) -> Optional[Dict[str, float]]:
        """Extrae dimensiones del mensaje"""
        # Patrones para dimensiones
        patrones = [
            r"(\d+(?:\.\d+)?)\s*[x√ó]\s*(\d+(?:\.\d+)?)",
            r"(\d+(?:\.\d+)?)\s*metros?\s*[x√ó]\s*(\d+(?:\.\d+)?)\s*metros?",
            r"(\d+(?:\.\d+)?)\s*m\s*[x√ó]\s*(\d+(?:\.\d+)?)\s*m",
        ]

        for patron in patrones:
            match = re.search(patron, mensaje, re.IGNORECASE)
            if match:
                try:
                    largo = float(match.group(1))
                    ancho = float(match.group(2))
                    return {"largo": largo, "ancho": ancho}
                except ValueError:
                    continue

        return None

    def _extraer_telefono(self, mensaje: str) -> Optional[str]:
        """Extrae n√∫mero de tel√©fono del mensaje"""
        patron = r"(\+?598\s?)?(\d{2,3}\s?\d{3}\s?\d{3})"
        match = re.search(patron, mensaje)
        if match:
            return match.group(0).replace(" ", "")
        return None

    def _extraer_nombre_apellido(self, mensaje: str) -> Optional[Dict[str, str]]:
        """Extrae nombre y apellido del mensaje"""
        # Buscar patrones comunes de presentaci√≥n
        # Ejemplos: "Me llamo Juan Perez", "Soy Maria Rodriguez", "Juan Perez"

        # Patr√≥n: "me llamo/soy + nombre apellido"
        patron_presentacion = r"(?:me llamo|soy|mi nombre es)\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)+)"
        match = re.search(patron_presentacion, mensaje, re.IGNORECASE)

        if match:
            nombre_completo = match.group(1).strip()
            partes = nombre_completo.split()
            if len(partes) >= 2:
                return {"nombre": partes[0], "apellido": " ".join(partes[1:])}

        # Patr√≥n: dos palabras capitalizadas consecutivas (sin palabras clave antes)
        # Solo si no hay otras palabras clave en el mensaje
        mensaje_limpio = mensaje.strip()
        palabras_clave = [
            "producto",
            "isodec",
            "poliestireno",
            "lana",
            "metro",
            "espesor",
            "precio",
        ]

        if not any(palabra in mensaje.lower() for palabra in palabras_clave):
            patron_nombre_simple = r"^([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)\s+([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*)$"
            match = re.match(patron_nombre_simple, mensaje_limpio)

            if match:
                return {"nombre": match.group(1), "apellido": match.group(2)}

        return None

    def _generar_respuesta_inteligente(
        self,
        mensaje: str,
        intencion: str,
        entidades: Dict[str, Any],
        contexto: ContextoConversacion,
    ) -> RespuestaIA:
        """Genera respuesta inteligente basada en el an√°lisis"""
        # Primero, intentar generar respuesta basada en intenci√≥n detectada
        # Solo usar base de conocimiento si no hay intenci√≥n clara o si la intenci√≥n es "general"

        # Respuestas gen√©ricas que debemos ignorar de la base de conocimiento
        respuestas_genericas = [
            "gracias por tu consulta",
            "te ayudo con la informaci√≥n",
            "puedo ayudarte con",
        ]

        # Si hay una intenci√≥n espec√≠fica detectada, usarla primero
        if intencion != "general":
            if intencion == "saludo":
                return self._manejar_saludo(contexto)
            elif intencion == "despedida":
                return self._manejar_despedida(contexto)
            elif intencion == "cotizacion":
                return self._manejar_cotizacion(entidades, contexto)
            elif intencion == "informacion":
                return self._manejar_informacion(entidades, contexto)
            elif intencion == "producto":
                return self._manejar_consulta_producto(entidades, contexto)
            elif intencion == "objecion":
                return self._manejar_objecion(mensaje, contexto)

        # Si intenci√≥n es "general", buscar en base de conocimiento
        # pero solo si la respuesta no es gen√©rica
        respuesta_conocimiento = self.base_conocimiento.obtener_respuesta_inteligente(
            mensaje, contexto.datos_cliente
        )

        if respuesta_conocimiento and len(respuesta_conocimiento) > 50:
            # Verificar si la respuesta es gen√©rica
            respuesta_lower = respuesta_conocimiento.lower()
            es_generica = any(
                generica in respuesta_lower for generica in respuestas_genericas
            )

            if not es_generica:
                # Usar respuesta de la base de conocimiento si no es gen√©rica
                return self._crear_respuesta(
                    respuesta_conocimiento, "informativa", 0.8, ["base_conocimiento"]
                )

        # Si llegamos aqu√≠, usar respuesta general
        return self._manejar_consulta_general(mensaje, contexto)

    def _manejar_saludo(self, contexto: ContextoConversacion) -> RespuestaIA:
        """Maneja saludos del cliente"""
        saludos = self.patrones_respuesta["saludo"]
        mensaje = random.choice(saludos)

        return self._crear_respuesta(
            mensaje, "informativa", 0.9, ["patrones_respuesta"]
        )

    def _manejar_despedida(self, contexto: ContextoConversacion) -> RespuestaIA:
        """Maneja despedidas del cliente"""
        despedidas = self.patrones_respuesta["despedida"]
        mensaje = random.choice(despedidas)

        return self._crear_respuesta(mensaje, "despedida", 0.9, ["patrones_respuesta"])

    def _manejar_cotizacion(
        self, entidades: Dict[str, Any], contexto: ContextoConversacion
    ) -> RespuestaIA:
        """Maneja solicitudes de cotizaci√≥n"""
        if contexto.estado_cotizacion == "inicial":
            contexto.estado_cotizacion = "recopilando_datos"
            mensaje = (
                "¬°Perfecto! Vamos a crear tu cotizaci√≥n paso a paso.\n\n"
                "Necesito algunos datos:\n"
                "1Ô∏è‚É£ ¬øCu√°l es tu nombre y apellido?\n"
                "2Ô∏è‚É£ ¬øCu√°l es tu tel√©fono?\n"
                "3Ô∏è‚É£ ¬øQu√© producto te interesa? (Isodec, Poliestireno, Lana de Roca)\n"
                "4Ô∏è‚É£ ¬øCu√°les son las dimensiones? (largo x ancho en metros)\n"
                "5Ô∏è‚É£ ¬øQu√© espesor necesitas? (50mm, 75mm, 100mm, 125mm, 150mm)"
            )

            return self._crear_respuesta(
                mensaje, "pregunta", 0.9, ["sistema_cotizaciones"]
            )

        elif contexto.estado_cotizacion == "recopilando_datos":
            # Actualizar datos del cliente con entidades extra√≠das
            if "nombre" in entidades:
                contexto.datos_cliente["nombre"] = entidades["nombre"]

            if "apellido" in entidades:
                contexto.datos_cliente["apellido"] = entidades["apellido"]

            if "telefono" in entidades:
                contexto.datos_cliente["telefono"] = entidades["telefono"]

            # Actualizar datos del producto con entidades extra√≠das
            if "productos" in entidades:
                contexto.datos_producto["producto"] = entidades["productos"][0]

            if "dimensiones" in entidades:
                contexto.datos_producto["largo"] = entidades["dimensiones"]["largo"]
                contexto.datos_producto["ancho"] = entidades["dimensiones"]["ancho"]

            if "espesores" in entidades:
                contexto.datos_producto["espesor"] = entidades["espesores"][0]

            # Construir contexto de validaci√≥n unificado
            contexto_validacion = construir_contexto_validacion(
                contexto.datos_cliente, contexto.datos_producto
            )

            # Usar validaci√≥n centralizada para verificar datos faltantes
            datos_faltantes = obtener_datos_faltantes(contexto_validacion)

            if datos_faltantes:
                # Hay datos faltantes, solicitar al cliente
                mensaje = formatear_mensaje_faltantes(datos_faltantes)
                return self._crear_respuesta(
                    mensaje, "pregunta", 0.8, ["sistema_cotizaciones"]
                )

            # Todos los datos est√°n completos, crear cotizaci√≥n
            cotizacion = self._crear_cotizacion(contexto)
            if cotizacion:
                contexto.estado_cotizacion = "cotizacion_completada"
                mensaje = self._formatear_cotizacion(cotizacion)
                return self._crear_respuesta(
                    mensaje, "cotizacion", 0.95, ["sistema_cotizaciones"]
                )
            else:
                # Error al crear cotizaci√≥n
                return self._crear_respuesta(
                    "Hubo un error al generar la cotizaci√≥n. ¬øPodr√≠as verificar los datos?",
                    "pregunta",
                    0.5,
                    ["sistema_cotizaciones"],
                )

        return self._crear_respuesta(
            "¬øEn qu√© m√°s puedo ayudarte?", "pregunta", 0.7, ["general"]
        )

    def _manejar_informacion(
        self, entidades: Dict[str, Any], contexto: ContextoConversacion
    ) -> RespuestaIA:
        """Maneja solicitudes de informaci√≥n"""
        if "productos" in entidades:
            producto = entidades["productos"][0]
            mensaje = self._obtener_informacion_producto(producto)
        else:
            mensaje = (
                "Tenemos varios productos de aislamiento t√©rmico:\n\n"
                "üè† **ISODEC** - Panel aislante con n√∫cleo EPS\n"
                "üß± **POLIESTIRENO** - Aislante b√°sico\n"
                "ü™® **LANA DE ROCA** - Aislante t√©rmico y ac√∫stico\n\n"
                "¬øSobre cu√°l te gustar√≠a saber m√°s?"
            )

        return self._crear_respuesta(mensaje, "informativa", 0.9, ["base_conocimiento"])

    def _manejar_consulta_producto(
        self, entidades: Dict[str, Any], contexto: ContextoConversacion
    ) -> RespuestaIA:
        """Maneja consultas espec√≠ficas sobre productos"""
        if "productos" in entidades:
            producto = entidades["productos"][0]
            mensaje = self._obtener_informacion_producto(producto)
        else:
            mensaje = "¬øSobre qu√© producto espec√≠fico te gustar√≠a informaci√≥n?"

        return self._crear_respuesta(mensaje, "informativa", 0.8, ["base_conocimiento"])

    def _manejar_objecion(
        self, mensaje: str, contexto: ContextoConversacion
    ) -> RespuestaIA:
        """Maneja objeciones del cliente"""
        mensaje_lower = mensaje.lower()

        if "caro" in mensaje_lower or "costoso" in mensaje_lower:
            respuesta = (
                "Entiendo tu preocupaci√≥n por el precio. Te explico el valor a largo plazo:\n\n"
                "‚úÖ Ahorro energ√©tico del 30-40%\n"
                "‚úÖ Durabilidad superior a 20 a√±os\n"
                "‚úÖ Incluye instalaci√≥n y garant√≠a\n"
                "‚úÖ Retorno de inversi√≥n en 3-5 a√±os\n\n"
                "¬øTe gustar√≠a que te muestre un c√°lculo de ahorro espec√≠fico?"
            )
        elif "no estoy seguro" in mensaje_lower:
            respuesta = (
                "Es normal tener dudas en una inversi√≥n importante. Te puedo ayudar:\n\n"
                "üìã Enviarte informaci√≥n detallada\n"
                "üìû Conectarte con nuestro t√©cnico\n"
                "üè† Mostrarte casos similares exitosos\n\n"
                "¬øQu√© te ayudar√≠a a decidir?"
            )
        else:
            respuesta = "Entiendo tu preocupaci√≥n. ¬øPodr√≠as contarme m√°s espec√≠ficamente qu√© te preocupa?"

        return self._crear_respuesta(
            respuesta, "informativa", 0.8, ["base_conocimiento", "objeciones"]
        )

    def _manejar_consulta_general(
        self, mensaje: str, contexto: ContextoConversacion
    ) -> RespuestaIA:
        """Maneja consultas generales"""
        mensaje = (
            "Puedo ayudarte con:\n\n"
            "üè† Informaci√≥n sobre productos de aislamiento\n"
            "üí∞ Cotizaciones personalizadas\n"
            "üìã Especificaciones t√©cnicas\n"
            "üîß Consultas sobre instalaci√≥n\n\n"
            "¬øEn qu√© te gustar√≠a que te ayude?"
        )

        return self._crear_respuesta(mensaje, "informativa", 0.7, ["general"])

    def _obtener_informacion_producto(self, producto: str) -> str:
        """Obtiene informaci√≥n detallada de un producto"""
        if producto == "isodec":
            return (
                "üè† **ISODEC - Panel Aislante T√©rmico**\n\n"
                "**Caracter√≠sticas principales:**\n"
                "‚úÖ N√∫cleo de EPS (Poliestireno Expandido)\n"
                "‚úÖ Excelente aislamiento t√©rmico\n"
                "‚úÖ F√°cil instalaci√≥n\n"
                "‚úÖ Durabilidad superior\n\n"
                "**Opciones disponibles:**\n"
                "üìè Espesores: 50mm, 75mm, 100mm, 125mm, 150mm\n"
                "üé® Colores: Blanco, Gris, Personalizado\n"
                "üîß Terminaciones: Gotero, Hormig√≥n, Aluminio\n\n"
                "üí∞ **Precio base:** $150/m¬≤ (100mm, Blanco)\n\n"
                "¬øTe interesa cotizar Isodec?"
            )
        elif producto == "poliestireno":
            return (
                "üß± **POLIESTIRENO EXPANDIDO**\n\n"
                "**Caracter√≠sticas principales:**\n"
                "‚úÖ Aislante t√©rmico b√°sico\n"
                "‚úÖ Bajo costo\n"
                "‚úÖ F√°cil manipulaci√≥n\n"
                "‚úÖ Ideal para proyectos b√°sicos\n\n"
                "üí∞ **Precio base:** $120/m¬≤ (100mm)\n\n"
                "¬øTe interesa cotizar Poliestireno?"
            )
        elif producto in ["lana", "lana_roca"]:
            return (
                "ü™® **LANA DE ROCA**\n\n"
                "**Caracter√≠sticas principales:**\n"
                "‚úÖ Aislante t√©rmico y ac√∫stico\n"
                "‚úÖ Resistente al fuego\n"
                "‚úÖ No t√≥xico\n"
                "‚úÖ Excelente durabilidad\n\n"
                "üí∞ **Precio base:** $140/m¬≤ (100mm)\n\n"
                "¬øTe interesa cotizar Lana de Roca?"
            )
        else:
            return "Producto no reconocido. ¬øPodr√≠as especificar cu√°l te interesa?"

    def _crear_cotizacion(self, contexto: ContextoConversacion):
        """Crea una cotizaci√≥n basada en los datos del contexto"""
        try:
            # Combinar nombre y apellido para el campo nombre del cliente
            nombre_completo = contexto.datos_cliente.get("nombre", "Cliente")
            apellido = contexto.datos_cliente.get("apellido", "")
            if apellido:
                nombre_completo = f"{nombre_completo} {apellido}"

            # Crear cliente
            cliente = Cliente(
                nombre=nombre_completo,
                telefono=contexto.datos_cliente.get("telefono", ""),
                direccion=contexto.datos_cliente.get("direccion", ""),
                zona=contexto.datos_cliente.get("zona", ""),
            )

            # Crear especificaciones
            especificaciones = EspecificacionCotizacion(
                producto=contexto.datos_producto.get("producto", "isodec"),
                espesor=contexto.datos_producto.get("espesor", "100mm"),
                relleno="EPS",
                largo_metros=Decimal(str(contexto.datos_producto.get("largo", 5))),
                ancho_metros=Decimal(str(contexto.datos_producto.get("ancho", 3))),
                color=contexto.datos_producto.get("color", "Blanco"),
                termina_front="Gotero",
                termina_sup="Gotero",
                termina_lat_1="Gotero",
                termina_lat_2="Gotero",
                anclajes="Incluido",
                traslado="Incluido",
            )

            # Crear cotizaci√≥n
            cotizacion = self.sistema_cotizaciones.crear_cotizacion(
                cliente=cliente,
                especificaciones=especificaciones,
                asignado_a="IA",
                observaciones="Cotizaci√≥n generada por IA conversacional",
            )

            return cotizacion

        except Exception as e:
            print(f"Error creando cotizaci√≥n: {e}")
            return None

    def _formatear_cotizacion(self, cotizacion) -> str:
        """Formatea una cotizaci√≥n para mostrar al cliente"""
        area = (
            cotizacion.especificaciones.largo_metros
            * cotizacion.especificaciones.ancho_metros
        )

        return (
            f"üéâ **¬°COTIZACI√ìN LISTA!**\n\n"
            f"üìã **ID:** {cotizacion.id}\n"
            f"üè† **Producto:** {cotizacion.especificaciones.producto.upper()}\n"
            f"üìè **Dimensiones:** {cotizacion.especificaciones.largo_metros}m x {cotizacion.especificaciones.ancho_metros}m\n"
            f"üìê **√Årea total:** {area} m¬≤\n"
            f"üìê **Espesor:** {cotizacion.especificaciones.espesor}\n"
            f"üé® **Color:** {cotizacion.especificaciones.color}\n\n"
            f"üí∞ **PRECIO POR M¬≤:** ${cotizacion.precio_metro_cuadrado}\n"
            f"üí∞ **PRECIO TOTAL:** ${cotizacion.precio_total}\n\n"
            f"‚úÖ **Incluye:** Material, terminaciones, anclajes y traslado\n\n"
            f"¬øTe parece bien esta cotizaci√≥n? ¬øNecesitas alg√∫n ajuste?"
        )

    def _crear_respuesta(
        self, mensaje: str, tipo: str, confianza: float, fuentes: List[str]
    ) -> RespuestaIA:
        """Crea una respuesta estructurada"""
        return RespuestaIA(
            mensaje=mensaje,
            tipo_respuesta=tipo,
            acciones_sugeridas=[],
            confianza=confianza,
            fuentes_conocimiento=fuentes,
            personalizacion={},
            timestamp=datetime.datetime.now(),
        )

    def _registrar_interaccion(
        self,
        mensaje_cliente: str,
        respuesta: RespuestaIA,
        contexto: ContextoConversacion,
    ):
        """Registra la interacci√≥n en la base de conocimiento"""
        interaccion = InteraccionCliente(
            id=f"ia_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}",
            timestamp=datetime.datetime.now(),
            cliente_id=contexto.cliente_id,
            tipo_interaccion="consulta_ia",
            mensaje_cliente=mensaje_cliente,
            respuesta_agente=respuesta.mensaje,
            contexto=contexto.datos_cliente,
            resultado="exitoso" if respuesta.confianza > 0.7 else "pendiente",
            satisfaccion_cliente=None,
        )

        self.base_conocimiento.registrar_interaccion(interaccion)

    def _actualizar_conocimiento_conversacion(
        self, contexto: ContextoConversacion, respuesta: RespuestaIA
    ):
        """Actualiza el conocimiento basado en la conversaci√≥n"""
        # Actualizar patrones de respuesta si la respuesta fue efectiva
        if respuesta.confianza > 0.8:
            tipo_respuesta = respuesta.tipo_respuesta
            if tipo_respuesta not in self.patrones_respuesta:
                self.patrones_respuesta[tipo_respuesta] = []

            if respuesta.mensaje not in self.patrones_respuesta[tipo_respuesta]:
                self.patrones_respuesta[tipo_respuesta].append(respuesta.mensaje)

        # OpenAI configuration
        self.use_ai = False
        self.openai_client = None
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
        # Pinecone configuration
        self.pinecone_index = None
        self.use_rag = False

        if OPENAI_AVAILABLE:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                try:
                    self.openai_client = OpenAI(api_key=api_key)
                    self.use_ai = True
                    print("‚úÖ OpenAI integration enabled")
                    
                    # Initialize Pinecone if OpenAI is working (needed for embeddings)
                    pinecone_key = os.getenv("PINECONE_API_KEY")
                    pinecone_index_name = os.getenv("PINECONE_INDEX_NAME", "chatbot-context")
                    
                    if pinecone_key:
                        try:
                            from pinecone import Pinecone
                            pc = Pinecone(api_key=pinecone_key)
                            self.pinecone_index = pc.Index(pinecone_index_name)
                            self.use_rag = True
                            print(f"‚úÖ Pinecone RAG enabled (Index: {pinecone_index_name})")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error initializing Pinecone: {e}")
                            self.use_rag = False
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Error initializing OpenAI: {e}")
                    self.use_ai = False
            else:
                print("‚ö†Ô∏è OPENAI_API_KEY not set, using pattern matching only")
        else:
            print("‚ö†Ô∏è OpenAI package not available, using pattern matching only")

        self.cargar_configuracion_inicial()

    def procesar_mensaje_usuario(
        self, mensaje: str, telefono_cliente: str, sesion_id: str = None
    ) -> Dict[str, Any]:
        """
        Procesa mensaje del usuario con workflow h√≠brido inteligente:
        - Pattern matching para intenciones simples (saludos, despedidas)
        - OpenAI para intenciones complejas (cotizaciones, consultas t√©cnicas)
        Retorna diccionario compatible con API
        """
        if not sesion_id:
            sesion_id = f"sesion_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}"

        # An√°lisis r√°pido de intenci√≥n (sin procesar completamente)
        intencion_rapida = self._analizar_intencion(mensaje)

        # Para todos los mensajes, intentamos usar OpenAI primero para mayor naturalidad
        if self.use_ai and self.openai_client:
            try:
                return self._procesar_con_openai(mensaje, telefono_cliente, sesion_id)
            except Exception as e:
                print(f"‚ö†Ô∏è Error con OpenAI, usando pattern matching: {e}")
                # Fallback a pattern matching solo si falla la IA
                return self._procesar_mensaje_patrones(
                    mensaje, telefono_cliente, sesion_id
                )
        else:
            # Si no hay IA configurada, usar pattern matching
            return self._procesar_mensaje_patrones(mensaje, telefono_cliente, sesion_id)

    def _procesar_con_openai(
        self, mensaje: str, telefono_cliente: str, sesion_id: str
    ) -> Dict[str, Any]:
        """Procesa mensaje usando OpenAI"""
        # Obtener contexto
        contexto = self._obtener_contexto_conversacion(telefono_cliente, sesion_id)

        # Obtener historial reciente
        historial = (
            contexto.mensajes_intercambiados[-5:]
            if len(contexto.mensajes_intercambiados) > 5
            else contexto.mensajes_intercambiados
        )

        # Obtener informaci√≥n de productos y precios para enriquecer el contexto
        # UPDATED: Pass the message to perform semantic search
        info_productos = self._obtener_info_productos_para_prompt(mensaje)
        estado_cotizacion = self._obtener_estado_cotizacion_para_prompt(contexto)

        # Construir historial de conversaci√≥n para OpenAI
        messages = [
            {
                "role": "system",
                "content": f"""Eres Superchapita, el asistente estrella de BMC Uruguay.
Tu misi√≥n es ayudar a los clientes a concretar sus proyectos de construcci√≥n y aislamiento con entusiasmo y profesionalismo.

TUS CAPACIDADES:
1. Experto en productos: Isodec, Poliestireno, Lana de Roca.
2. Generador de Cotizaciones: Pide los datos necesarios (producto, medidas, espesor) y gu√≠a al usuario.
3. Asesor T√©cnico: Resuelve dudas sobre instalaci√≥n y beneficios.

PERSONALIDAD Y TONO:
- Eres din√°mico, servicial y proactivo.
- EVITA RESPUESTAS ROB√ìTICAS O REPETITIVAS.
- No empieces siempre con "Hola" o "Soy Superchapita". Var√≠a tus saludos y estructuras.
- Usa emojis con naturalidad pero sin saturar (üëç, üè†, ‚ú®).
- Habla en espa√±ol de Uruguay (puedes usar "t√∫" o "vos" seg√∫n el contexto, pero mant√©n consistencia).

CONTEXTO RELEVANTE (RAG):
{info_productos}

{estado_cotizacion}

INSTRUCCIONES DE RESPUESTA:
- Si el usuario saluda, responde con algo diferente cada vez (ej: "¬°Buenas! ¬øEn qu√© proyecto est√°s trabajando hoy?", "¬°Hola! Listo para aislar tu hogar").
- Si piden cotizaci√≥n, pide SOLO los datos que faltan. No pidas todo si ya te dieron algo.
- Si detectas una duda (ej: "es caro"), explica el valor/retorno de inversi√≥n, no solo digas "es barato".

IMPORTANTE: Debes responder SIEMPRE en formato JSON con esta estructura exacta:
{{
  "mensaje": "tu respuesta al cliente aqu√≠",
  "tipo": "cotizacion|informacion|pregunta|seguimiento|general",
  "acciones": ["accion1", "accion2"],
  "confianza": 0.95,
  "necesita_datos": ["dato1", "dato2"]
}}

El campo "tipo" debe ser uno de: cotizacion, informacion, pregunta, seguimiento, general.
El campo "confianza" debe ser un n√∫mero entre 0.0 y 1.0.
El campo "necesita_datos" debe ser una lista de datos que faltan para completar una cotizaci√≥n (ej: ["producto", "dimensiones", "espesor"]).""",
            }
        ]

        # Agregar historial
        for msg in historial:
            if msg["tipo"] == "cliente":
                messages.append({"role": "user", "content": msg["mensaje"]})
            else:
                messages.append({"role": "assistant", "content": msg["mensaje"]})

        # Agregar mensaje actual
        messages.append({"role": "user", "content": mensaje})

        # Llamar a OpenAI
        response = self.openai_client.chat.completions.create(
            model=self.openai_model,
            messages=messages,
            temperature=0.7,
            response_format={"type": "json_object"},
        )

        # Parsear respuesta
        resultado = json.loads(response.choices[0].message.content)

        # Actualizar contexto
        self._actualizar_contexto(contexto, mensaje)
        contexto.mensajes_intercambiados.append(
            {
                "tipo": "ia",
                "mensaje": resultado.get("mensaje", ""),
                "timestamp": datetime.datetime.now().isoformat(),
            }
        )

        # Crear respuesta estructurada
        respuesta_ia = self._crear_respuesta(
            resultado.get("mensaje", ""),
            resultado.get("tipo", "general"),
            float(resultado.get("confianza", 0.8)),
            ["openai"],
        )

        # Registrar interacci√≥n
        self._registrar_interaccion(mensaje, respuesta_ia, contexto)

        # Retornar formato API
        return {
            "mensaje": resultado.get("mensaje", ""),
            "tipo": resultado.get("tipo", "general"),
            "acciones": resultado.get("acciones", []),
            "confianza": float(resultado.get("confianza", 0.8)),
            "necesita_datos": resultado.get("necesita_datos", []),
            "sesion_id": sesion_id,
            "timestamp": datetime.datetime.now().isoformat(),
        }

    def _obtener_info_productos_para_prompt(self, query: str = "") -> str:
        """Obtiene informaci√≥n de productos para enriquecer el prompt de OpenAI
           Usa RAG (Pinecone) si est√° disponible, sino usa lista est√°tica.
        """
        
        # 1. Try Vector Search (RAG)
        if self.use_rag and self.pinecone_index and query:
            try:
                # Generate embedding
                emb_response = self.openai_client.embeddings.create(
                    input=query,
                    model="text-embedding-3-small"
                )
                embedding = emb_response.data[0].embedding
                
                # Query Pinecone
                results = self.pinecone_index.query(
                    vector=embedding,
                    top_k=3,
                    include_metadata=True
                )
                
                if results and results.matches:
                    context_parts = ["INFORMACI√ìN ENCONTRADA EN BASE DE CONOCIMIENTO:"]
                    for match in results.matches:
                        if match.metadata and "text" in match.metadata:
                            context_parts.append(f"- {match.metadata['text']}")
                    
                    return "\n".join(context_parts)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error querying Pinecone: {e}")
                # Fallback to static list below
        
        # 2. Static Fallback (Legacy)
        productos_info = []

        # Obtener precios actuales
        precios = {
            "isodec": self.sistema_cotizaciones.obtener_precio_producto("isodec"),
            "poliestireno": self.sistema_cotizaciones.obtener_precio_producto(
                "poliestireno"
            ),
            "lana_roca": self.sistema_cotizaciones.obtener_precio_producto("lana_roca"),
        }

        productos_info.append("PRODUCTOS DISPONIBLES (Catalog Base):")
        productos_info.append("1. ISODEC - Panel aislante con n√∫cleo EPS")
        productos_info.append(
            f"   Precio base: ${precios.get('isodec', 150):.2f} por m¬≤"
        )
        productos_info.append(
            "   Caracter√≠sticas: Excelente aislamiento t√©rmico, f√°cil instalaci√≥n"
        )

        productos_info.append("2. POLIESTIRENO - Aislante b√°sico")
        productos_info.append(
            f"   Precio base: ${precios.get('poliestireno', 120):.2f} por m¬≤"
        )
        productos_info.append("   Caracter√≠sticas: Aislante econ√≥mico y eficiente")

        productos_info.append("3. LANA DE ROCA - Aislante t√©rmico y ac√∫stico")
        productos_info.append(
            f"   Precio base: ${precios.get('lana_roca', 140):.2f} por m¬≤"
        )
        productos_info.append(
            "   Caracter√≠sticas: Aislamiento t√©rmico y ac√∫stico superior"
        )

        productos_info.append(
            "\nESPESORES DISPONIBLES: 50mm, 75mm, 100mm, 125mm, 150mm"
        )
        productos_info.append("COLORES DISPONIBLES: Blanco, Gris, Beige")

        return "\n".join(productos_info)

    def _obtener_estado_cotizacion_para_prompt(
        self, contexto: ContextoConversacion
    ) -> str:
        """Obtiene el estado actual de cotizaci√≥n para enriquecer el prompt"""
        if contexto.estado_cotizacion == "inicial":
            return ""

        estado_info = [
            f"ESTADO ACTUAL DE LA COTIZACI√ìN: {contexto.estado_cotizacion.upper()}"
        ]

        if contexto.datos_cliente:
            estado_info.append(
                f"Datos del cliente: {json.dumps(contexto.datos_cliente, ensure_ascii=False)}"
            )

        if contexto.datos_producto:
            estado_info.append(
                f"Datos del producto: {json.dumps(contexto.datos_producto, ensure_ascii=False)}"
            )

        if contexto.estado_cotizacion == "recopilando_datos":
            datos_faltantes = []
            if not contexto.datos_producto.get("producto"):
                datos_faltantes.append("producto")
            if not contexto.datos_producto.get(
                "largo"
            ) or not contexto.datos_producto.get("ancho"):
                datos_faltantes.append("dimensiones")
            if not contexto.datos_producto.get("espesor"):
                datos_faltantes.append("espesor")

            if datos_faltantes:
                estado_info.append(f"DATOS FALTANTES: {', '.join(datos_faltantes)}")

        return "\n".join(estado_info) if len(estado_info) > 1 else ""

    def _procesar_mensaje_patrones(
        self, mensaje: str, telefono_cliente: str, sesion_id: str
    ) -> Dict[str, Any]:
        """Procesa mensaje usando pattern matching (fallback)"""
        respuesta = self.procesar_mensaje(mensaje, telefono_cliente, sesion_id)

        # Convertir RespuestaIA a formato API
        return {
            "mensaje": respuesta.mensaje,
            "tipo": respuesta.tipo_respuesta,
            "acciones": respuesta.acciones_sugeridas,
            "confianza": respuesta.confianza,
            "necesita_datos": [],
            "sesion_id": sesion_id,
            "timestamp": respuesta.timestamp.isoformat(),
        }

    def exportar_conocimiento_ia(self, archivo: str):
        """Exporta todo el conocimiento de la IA"""
        conocimiento_ia = {
            "patrones_respuesta": self.patrones_respuesta,
            "entidades_reconocidas": self.entidades_reconocidas,
            "conversaciones_activas": {
                k: {
                    "cliente_id": v.cliente_id,
                    "sesion_id": v.sesion_id,
                    "estado_cotizacion": v.estado_cotizacion,
                    "timestamp_inicio": v.timestamp_inicio.isoformat(),
                    "timestamp_ultima_actividad": v.timestamp_ultima_actividad.isoformat(),
                }
                for k, v in self.conversaciones_activas.items()
            },
            "fecha_exportacion": datetime.datetime.now().isoformat(),
        }

        with open(archivo, "w", encoding="utf-8") as f:
            json.dump(conocimiento_ia, f, ensure_ascii=False, indent=2)


def main():
    """Funci√≥n principal para demostrar la IA conversacional"""
    print("IA Conversacional Integrada BMC Uruguay")
    print("=" * 50)

    # Crear IA
    ia = IAConversacionalIntegrada()

    # Simular conversaci√≥n
    mensajes_simulados = [
        "Hola, necesito informaci√≥n sobre Isodec",
        "Quiero cotizar para mi casa, 10 metros por 5 metros",
        "100mm, blanco",
        "Perfecto, me parece bien el precio",
    ]

    cliente_id = "cliente_demo"

    for mensaje in mensajes_simulados:
        print(f"\nüë§ Cliente: {mensaje}")
        respuesta = ia.procesar_mensaje(mensaje, cliente_id)
        print(f"ü§ñ IA: {respuesta.mensaje}")
        print(f"   Confianza: {respuesta.confianza:.2f}")
        print(f"   Fuentes: {', '.join(respuesta.fuentes_conocimiento)}")

    # Exportar conocimiento
    ia.exportar_conocimiento_ia("ia_conversacional.json")
    print("\nConocimiento de IA exportado a ia_conversacional.json")


if __name__ == "__main__":
    main()
